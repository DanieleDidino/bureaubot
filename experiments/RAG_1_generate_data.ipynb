{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bdd511-4fc0-4bbd-9f4b-df76bbcb756a",
   "metadata": {},
   "source": [
    "# Generate Synthetic Dataset with LLM\n",
    "\n",
    "Reference: [Fine-Tuning Embeddings for RAG with Synthetic Data](https://medium.com/llamaindex-blog/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971)\n",
    "\n",
    "Generate a synthetic dataset of (query, relevant documents) pairs from a corpus of **documents without labelers** by leveraging LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b48882-dd24-4872-a42c-f21ac303e550",
   "metadata": {},
   "source": [
    "## Generate Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c262e939-9eef-421e-8a94-c1d8a6cf861d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.schema import MetadataMode\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32eaaf6b-e3dc-4838-aaf5-f1d6305e2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = ['afa_docs/merkblatt-fuer-arbeitslose_ba036520.pdf']\n",
    "VAL_FILES = ['afa_docs/dok_ba035980.pdf']\n",
    "\n",
    "TRAIN_CORPUS_FPATH = 'afa_docs/train_corpus.json'\n",
    "VAL_CORPUS_FPATH = 'afa_docs/val_corpus.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ca90b0-eac9-420f-b6e9-a83749280b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(files, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Loading files {files}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(input_files=files)\n",
    "    docs = reader.load_data()\n",
    "    if verbose:\n",
    "        print(f'Loaded {len(docs)} docs')\n",
    "    \n",
    "    parser = SimpleNodeParser.from_defaults()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Parsed {len(nodes)} nodes')\n",
    "\n",
    "    corpus = {node.node_id: node.get_content(metadata_mode=MetadataMode.NONE) for node in nodes}\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9695c651",
   "metadata": {},
   "source": [
    "## TODO\n",
    "RANDOMIZE THE TRAIN/VAL SETS <----------------------------------------------------------\n",
    "\n",
    "NOW IT USED A PDF FOR TRAIN AND THE OTHER FOR VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15af0b0c-547c-493a-8fea-1d880c3c63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files ['afa_docs/merkblatt-fuer-arbeitslose_ba036520.pdf']\n",
      "Loaded 103 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniele/Desktop/Projects/DSR_project_ideas/venv_DSR_project_ideas/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing documents into nodes: 100%|██████████| 103/103 [00:00<00:00, 3038.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 103 nodes\n",
      "Loading files ['afa_docs/dok_ba035980.pdf']\n",
      "Loaded 40 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents into nodes: 100%|██████████| 40/40 [00:00<00:00, 3403.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 40 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_corpus = load_corpus(TRAIN_FILES, verbose=True)\n",
    "val_corpus = load_corpus(VAL_FILES, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5566271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'dict'>\n",
      "Length: 103\n",
      "49466_BA_MB_1.indd   1 10.02.2015   13:20:58Agentur für Arbeit  \n",
      "Musterstadthausen  Merkblatt\n",
      "1Merkblatt für\n",
      "Arbeitslose \n",
      "Ihre Rechte –\n",
      "Ihre Pflichten\n",
      "--------------------------------------------------------------------------------\n",
      "3 \n",
      "Ihre Agentur für Arbeit hält eine Fülle von \n",
      " Informationen für Sie bereit. \n",
      "Neben den Informationen in diesem Merkblatt finden \n",
      "Sie unter » www.arbeitsagentur.de  unser umfassen ­\n",
      "des Online-Angebot der „eServices “ sowie ein \n",
      " interessantes Informationsangebot aus allen Aufgaben ­\n",
      "bereichen der Bundesagentur für Arbeit. Sie erhalten \n",
      "wertvolle Tipps zu den Themen Ausbil ­\n",
      "dung, Berufs- und Studienwahl, Weiter ­\n",
      "bildung, wichtige Informationen über \n",
      "Geldleistungen sowie ein umfangreiches \n",
      "Serviceangebot.\n",
      "Über das Job- und Serviceportal  \n",
      "» www.arbeitsagentur.de  können Sie beispielsweise:\n",
      "•  sich arbeitsuchend und arbeitslos melden,\n",
      "•  Geldleistungen, wie Arbeitslosengeld, beantragen\n",
      "•  Fragen zum Arbeitslosengeld unserem Chatbot \n",
      " stellen\n",
      "• Stellenangebote über die Jobsuche finden\n",
      "• Vermittlungsvorschläge und Stellenempfehlungen \n",
      "einsehen und sich bewerben\n",
      "•  Bescheide einsehen \n",
      "•  die Postfachnachricht nutzen – eine sichere \n",
      " Alternative zur E-Mail \n",
      "und vieles mehr\n",
      "Wenden Sie sich bitte an das Service Center bzw. den \n",
      "Empfang in Ihrer Agentur für Arbeit, wenn Sie weitere \n",
      "Informationen über das Verfahren und die Vorteile \n",
      " erhalten möchten.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type: {type(train_corpus)}\")\n",
    "print(f\"Length: {len(train_corpus)}\")\n",
    "for key in list(train_corpus.keys())[0:2]:\n",
    "    print(train_corpus[key])\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f8838e-96d0-4def-978b-61bd1dce3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_CORPUS_FPATH, 'w+') as f:\n",
    "    json.dump(train_corpus, f)\n",
    "\n",
    "with open(VAL_CORPUS_FPATH, 'w+') as f:\n",
    "    json.dump(val_corpus, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08491e5-6273-4b09-b19f-bbf3276d562b",
   "metadata": {},
   "source": [
    "## Generate synthetic queries\n",
    "\n",
    "Use an LLM (e.g., gpt-3.5-turbo) to generate questions using each text chunk in the corpus as context.\n",
    "\n",
    "For both training and validation, it creates pairs (`generated question`, `text chunk as context`).These pairs are used as data points in the finetuning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48e338f-0cf0-497b-988b-5a7d112b3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_QUERIES_FPATH = 'afa_docs/train_val_data/train_queries.json'\n",
    "TRAIN_RELEVANT_DOCS_FPATH = 'afa_docs/train_val_data/train_relevant_docs.json'\n",
    "\n",
    "VAL_QUERIES_FPATH = 'afa_docs/train_val_data/val_queries.json'\n",
    "VAL_RELEVANT_DOCS_FPATH = 'afa_docs/train_val_data/val_relevant_docs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bfeb3cd-59fd-496c-a4f0-c269835123ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_CORPUS_FPATH, 'r+') as f:\n",
    "    train_corpus = json.load(f)\n",
    "\n",
    "with open(VAL_CORPUS_FPATH, 'r+') as f:\n",
    "    val_corpus = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c26a5cd-9ec4-4c7b-bc58-9349d83a248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(\n",
    "    corpus,\n",
    "    num_questions_per_chunk=2,\n",
    "    prompt_template=None,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Automatically generate hypothetical questions that could be answered with\n",
    "    doc in the corpus.\n",
    "    \"\"\"\n",
    "    llm = OpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "    prompt_template = prompt_template or \"\"\"\\\n",
    "    Context information is below.\n",
    "    \n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    \n",
    "    Given the context information and not prior knowledge.\n",
    "    generate only questions based on the below query.\n",
    "    \n",
    "    You are a Teacher/ Professor. Your task is to setup \\\n",
    "    {num_questions_per_chunk} questions for an upcoming \\\n",
    "    quiz/examination. The questions should be diverse in nature \\\n",
    "    across the document. Restrict the questions to the \\\n",
    "    context information provided.\"\n",
    "    \"\"\"\n",
    "\n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "    # for node_id, text in corpus.items():\n",
    "    for node_id, text in tqdm(corpus.items()):\n",
    "        query = prompt_template.format(context_str=text, num_questions_per_chunk=num_questions_per_chunk)\n",
    "        response = llm.complete(query)\n",
    " \n",
    "        result = str(response).strip().split(\"\\n\")\n",
    "        questions = [\n",
    "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
    "        ]\n",
    "        questions = [question for question in questions if len(question) > 0]\n",
    "        \n",
    "        for question in questions:\n",
    "            question_id = str(uuid.uuid4())\n",
    "            queries[question_id] = question\n",
    "            relevant_docs[question_id] = [node_id]\n",
    "    return queries, relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14746744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_small = dict()\n",
    "i = 0\n",
    "for key, value in train_corpus.items():\n",
    "    train_corpus_small[key] = value\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37cc58cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8• Unter Umständen müssen Sie mit dem Wegfall der \n",
      "Leistung oder mit Sperrzeiten rechnen, wenn Sie\n",
      "•  sich nicht selbst aktiv um Arbeit bemühen,\n",
      "•  die während Ihrer Arbeitslosigkeit von der Agentur \n",
      "für Arbeit geforderten Eigenbemühungen nicht \n",
      "nachweisen,\n",
      "•  zumutbare Arbeitsmöglichkeiten nicht nutzen,\n",
      "•  Eingliederungsmaßnahmen (z.  B. Maßnahmen  \n",
      "der beruflichen Weiterbildung oder Maßnahmen \n",
      "zur Aktivierung und beruflichen Eingliederung)  \n",
      "ablehnen  \n",
      "oder\n",
      "•  einer Aufforderung, sich zu melden oder zu einem \n",
      "Untersuchungstermin zu erscheinen, nicht folgen.\n",
      "• Bitte melden Sie Ihrer zuständigen Agentur für Arbeit \n",
      "sofort alle Änderungen, die Ihren Leistungsanspruch \n",
      "beeinflussen. Teilen Sie bitte insbesondere umge ­\n",
      "hend jede Änderung des Familienstandes, der Lohn ­\n",
      "steuerklasse und des Faktors mit. Wenn Sie mit Ihrer \n",
      "Ehegattin / Ihrem Ehegatten oder in einer eingetrage ­\n",
      "nen Lebenspartnerschaft die Lohnsteuerklassen \n",
      "wechseln, lassen Sie sich wegen der  finanziellen \n",
      "Auswirkungen unbedingt vor dem Lohnsteuerklassen ­\n",
      "wechsel bei Ihrer Agentur für Arbeit beraten. Weitere \n",
      "Hinweise dazu finden Sie in Abschnitt 8.2. und Ab ­\n",
      "schnitt 4.\n",
      "• Bitte melden Sie Ihrer Agentur für Arbeit vorab jeden \n",
      "Umzug oder eine geplante Ortsabwesenheit (Urlaub/\n",
      "Reise). Weitere Hinweise dazu finden Sie in \n",
      "»  Abschnitt 8.2 und »  Abschnitt 2.5 .\n",
      "• Das Arbeitslosengeld wird bargeldlos ausgezahlt. \n",
      "Richten Sie deshalb bitte ein Konto ein, falls noch \n",
      "nicht geschehen.\n",
      "• Die Entscheidung über Ihren Antrag wird Ihnen durch \n",
      "einen schriftlichen Bescheid bekannt gegeben.Das Wichtigste vorweg\n"
     ]
    }
   ],
   "source": [
    "page = list(train_corpus_small.keys())[6] # a page in the document\n",
    "print(train_corpus_small[page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5231d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_corpus_small = dict()\n",
    "i = 0\n",
    "for key, value in val_corpus.items():\n",
    "    val_corpus_small[key] = value\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ee4c7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7Inhaltsverzeichnis\n",
      "5 Sie haben in Deutschland  gearbeitet  \n",
      "und haben als Grenzgängerin bzw.  \n",
      "Grenzgänger im (benach  barten) Ausland  \n",
      "gewohnt?  31\n",
      "5.1 Zusätzliche Arbeitsuchendmeldung von \n",
      " Grenzgängerinnen bzw. Grenzgängern im  \n",
      "bisherigen Beschäftigungsstaat  31\n",
      "5.2 Arbeitslosengeld ausnahmsweise  \n",
      "von Deutschland  32\n",
      "5.3 Auswirkungen auf Ansprüche der Deutschen \n",
      "Rentenversicherung  32\n",
      "6 Sonderregelungen  34\n",
      "6.1 Drittstaatsangehörige  34\n",
      "6.2 Staaten der früheren SFR Jugoslawien  \n",
      "( außer Slowenien und Kroatien)  35\n",
      "7 Was Sie sonst noch wissen sollten  37\n",
      "Anhänge\n",
      "Anhang 1: Zuständige Stellen  38\n",
      "Anhang 2: Weitere Merkblätter  39\n"
     ]
    }
   ],
   "source": [
    "page = list(val_corpus_small.keys())[6] # a page in the document\n",
    "print(val_corpus_small[page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84780125-1c09-4904-bce1-23586d012c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:49<00:00,  4.52s/it]\n"
     ]
    }
   ],
   "source": [
    "train_queries, train_relevant_docs = generate_queries(train_corpus_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9452dcfc-7084-496f-87eb-8c7be6a6dc6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:45<00:00,  4.11s/it]\n"
     ]
    }
   ],
   "source": [
    "val_queries, val_relevant_docs = generate_queries(val_corpus_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96087eb2-607b-4115-ab37-426bfcf6af1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(TRAIN_QUERIES_FPATH, 'w+') as f:\n",
    "    json.dump(train_queries, f)\n",
    "\n",
    "with open(TRAIN_RELEVANT_DOCS_FPATH, 'w+') as f:\n",
    "    json.dump(train_relevant_docs, f)\n",
    "\n",
    "with open(VAL_QUERIES_FPATH, 'w+') as f:\n",
    "    json.dump(val_queries, f)\n",
    "\n",
    "with open(VAL_RELEVANT_DOCS_FPATH, 'w+') as f:\n",
    "    json.dump(val_relevant_docs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71453dc5-25e0-45bf-9d86-5e72b3a891d5",
   "metadata": {},
   "source": [
    "## Merge data\n",
    "\n",
    "Reorganize the data for easier accessing the training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f465498-daa5-41b3-9ea3-8114254832b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_FPATH = 'afa_docs/train_val_data/train_dataset.json'\n",
    "VAL_DATASET_FPATH = 'afa_docs/train_val_data/val_dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430e34b0-699d-4eec-a26d-6d100d81cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = {\n",
    "    'queries': train_queries,\n",
    "    'corpus': train_corpus,\n",
    "    'relevant_docs': train_relevant_docs,\n",
    "}\n",
    "\n",
    "val_dataset = {\n",
    "    'queries': val_queries,\n",
    "    'corpus': val_corpus,\n",
    "    'relevant_docs': val_relevant_docs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b09071a2-6c32-408a-b971-39b5d6e42486",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATASET_FPATH, 'w+') as f:\n",
    "    json.dump(train_dataset, f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'w+') as f:\n",
    "    json.dump(val_dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
