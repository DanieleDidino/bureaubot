{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bdd511-4fc0-4bbd-9f4b-df76bbcb756a",
   "metadata": {},
   "source": [
    "# Generate Synthetic Dataset with LLM\n",
    "\n",
    "Reference: [Fine-Tuning Embeddings for RAG with Synthetic Data](https://medium.com/llamaindex-blog/fine-tuning-embeddings-for-rag-with-synthetic-data-e534409a3971)\n",
    "\n",
    "Generate a synthetic dataset of (query, relevant documents) pairs from a corpus of **documents without labelers** by leveraging LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b48882-dd24-4872-a42c-f21ac303e550",
   "metadata": {},
   "source": [
    "## Generate Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c262e939-9eef-421e-8a94-c1d8a6cf861d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.schema import MetadataMode\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32eaaf6b-e3dc-4838-aaf5-f1d6305e2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = ['data_finetuning/one_file/merkblatt-fuer-arbeitslose_ba036520.pdf']\n",
    "corpus_fpath = 'data_finetuning/one_file/corpus.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f81301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = SimpleDirectoryReader(input_files=files_list)\n",
    "\n",
    "# docs = reader.load_data()  \n",
    "\n",
    "# parser = SimpleNodeParser.from_defaults()\n",
    "\n",
    "# nodes = parser.get_nodes_from_documents(docs, show_progress=False)\n",
    "\n",
    "# list(nodes[0])\n",
    "\n",
    "# nodes[4].get_content(metadata_mode=MetadataMode.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6ca90b0-eac9-420f-b6e9-a83749280b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(files, verbose=False):\n",
    "    \"\"\"\n",
    "    Load the files with \"SimpleDirectoryReader\", split the document with \"SimpleNodeParser\"\n",
    "    and extract the text.\n",
    "\n",
    "    Args:\n",
    "        files (str or list): The folder with the files or a list of filenames.\n",
    "        verbose (bool): Whether or not print info (True/Flase)\n",
    "\n",
    "    Returns:\n",
    "        A query engine to use to send queries to a LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Loading files {files}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(input_files=files)\n",
    "    docs = reader.load_data()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Loaded {len(docs)} docs')\n",
    "    \n",
    "    parser = SimpleNodeParser.from_defaults()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Parsed {len(nodes)} nodes')\n",
    "\n",
    "    corpus = {node.node_id: node.get_content(metadata_mode=MetadataMode.NONE) for node in nodes}\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15af0b0c-547c-493a-8fea-1d880c3c63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files ['data_finetuning/one_file/merkblatt-fuer-arbeitslose_ba036520.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniele/Desktop/Projects/DSR_project_ideas/venv_DSR_project_ideas/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 103 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing documents into nodes: 100%|██████████| 103/103 [00:00<00:00, 2994.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 103 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = load_corpus(files_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8dccd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'dict'>\n",
      "Length: 103\n",
      "49466_BA_MB_1.indd   1 10.02.2015   13:20:58Agentur für Arbeit  \n",
      "Musterstadthausen  Merkblatt\n",
      "1Merkblatt für\n",
      "Arbeitslose \n",
      "Ihre Rechte –\n",
      "Ihre Pflichten\n",
      "--------------------------------------------------------------------------------\n",
      "3 \n",
      "Ihre Agentur für Arbeit hält eine Fülle von \n",
      " Informationen für Sie bereit. \n",
      "Neben den Informationen in diesem Merkblatt finden \n",
      "Sie unter » www.arbeitsagentur.de  unser umfassen ­\n",
      "des Online-Angebot der „eServices “ sowie ein \n",
      " interessantes Informationsangebot aus allen Aufgaben ­\n",
      "bereichen der Bundesagentur für Arbeit. Sie erhalten \n",
      "wertvolle Tipps zu den Themen Ausbil ­\n",
      "dung, Berufs- und Studienwahl, Weiter ­\n",
      "bildung, wichtige Informationen über \n",
      "Geldleistungen sowie ein umfangreiches \n",
      "Serviceangebot.\n",
      "Über das Job- und Serviceportal  \n",
      "» www.arbeitsagentur.de  können Sie beispielsweise:\n",
      "•  sich arbeitsuchend und arbeitslos melden,\n",
      "•  Geldleistungen, wie Arbeitslosengeld, beantragen\n",
      "•  Fragen zum Arbeitslosengeld unserem Chatbot \n",
      " stellen\n",
      "• Stellenangebote über die Jobsuche finden\n",
      "• Vermittlungsvorschläge und Stellenempfehlungen \n",
      "einsehen und sich bewerben\n",
      "•  Bescheide einsehen \n",
      "•  die Postfachnachricht nutzen – eine sichere \n",
      " Alternative zur E-Mail \n",
      "und vieles mehr\n",
      "Wenden Sie sich bitte an das Service Center bzw. den \n",
      "Empfang in Ihrer Agentur für Arbeit, wenn Sie weitere \n",
      "Informationen über das Verfahren und die Vorteile \n",
      " erhalten möchten.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type: {type(corpus)}\")\n",
    "print(f\"Length: {len(corpus)}\")\n",
    "for key in list(corpus.keys())[0:2]:\n",
    "    print(corpus[key])\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92f8838e-96d0-4def-978b-61bd1dce3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus_fpath, 'w+') as f:\n",
    "    json.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08491e5-6273-4b09-b19f-bbf3276d562b",
   "metadata": {},
   "source": [
    "## Generate synthetic queries\n",
    "\n",
    "Use an LLM (e.g., gpt-3.5-turbo) to generate questions using each text chunk in the corpus as context.\n",
    "\n",
    "For both training and validation, it creates pairs (`generated question`, `text chunk as context`).These pairs are used as data points in the finetuning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e48e338f-0cf0-497b-988b-5a7d112b3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries_fpath = 'data_finetuning/one_file/train_val_data/train_queries.json'\n",
    "train_relevant_docs_fpath = 'data_finetuning/one_file/train_val_data/train_relevant_docs.json'\n",
    "\n",
    "val_queries_fpath = 'data_finetuning/one_file/train_val_data/val_queries.json'\n",
    "val_relevant_docs_fpath = 'data_finetuning/one_file/train_val_data/val_relevant_docs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bfeb3cd-59fd-496c-a4f0-c269835123ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus_fpath, 'r+') as f:\n",
    "    json.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c26a5cd-9ec4-4c7b-bc58-9349d83a248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(corpus, num_questions_per_chunk=2, num_val_questions=1, prompt_template=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Generate hypothetical questions that could be answered with documents in the corpus.\n",
    "\n",
    "    Args:\n",
    "        corpus (dict): A dictionary with {\"node_id\":\"text\"} format\n",
    "        num_questions_per_chunk (int): number of questions to generate\n",
    "        num_val_questions (int): Number of questions to use in the validation set (\"num_val_questions\" < \"num_questions_per_chunk\")\n",
    "        prompt_template (f-string): A custom prompt to use to generate the questions\n",
    "        verbose (bool): Whether or not print info (True/Flase) - TODO\n",
    "\n",
    "    Returns:\n",
    "        queries: \n",
    "        relevant_docs: \n",
    "    \"\"\"\n",
    "\n",
    "    if not (num_val_questions < num_questions_per_chunk):\n",
    "        print(\"num_val_questions must be less than num_questions_per_chunk\")\n",
    "        return None\n",
    "    \n",
    "    llm = OpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "    prompt_template = prompt_template or \"\"\"\\\n",
    "    Context information is below.\n",
    "    \n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "    \n",
    "    Given the context information and not prior knowledge,\n",
    "    generate only questions based on the below query.\n",
    "    \n",
    "    You are a Teacher/ Professor. Your task is to setup \\\n",
    "    {num_questions_per_chunk} questions for an upcoming \\\n",
    "    quiz/examination. The questions should be diverse in nature \\\n",
    "    across the document. Restrict the questions to the \\\n",
    "    context information provided.\"\n",
    "    \"\"\"\n",
    "\n",
    "    queries_train = {}\n",
    "    relevant_docs_train = {}\n",
    "\n",
    "    queries_val = {}\n",
    "    relevant_docs_val = {}\n",
    "\n",
    "\n",
    "    # for node_id, text in corpus.items():\n",
    "    for node_id, text in tqdm(corpus.items()):\n",
    "        query = prompt_template.format(context_str=text, num_questions_per_chunk=num_questions_per_chunk)\n",
    "        response = llm.complete(query)\n",
    " \n",
    "        result = str(response).strip().split(\"\\n\")\n",
    "        questions = [\n",
    "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
    "        ]\n",
    "        \n",
    "        questions = [question for question in questions if len(question) > 0]\n",
    "        split_index = num_questions_per_chunk - num_val_questions\n",
    "        questions_train = questions[:split_index]\n",
    "        questions_val = questions[split_index:]\n",
    "\n",
    "        for question in questions_train:\n",
    "            question_id = str(uuid.uuid4())\n",
    "            queries_train[question_id] = question\n",
    "            relevant_docs_train[question_id] = [node_id]\n",
    "        \n",
    "        for question in questions_val:\n",
    "            question_id = str(uuid.uuid4())\n",
    "            queries_val[question_id] = question\n",
    "            relevant_docs_val[question_id] = [node_id]\n",
    "\n",
    "    return queries_train, relevant_docs_train, queries_val, relevant_docs_val # queries, relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36638893",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_small = dict()\n",
    "i = 0\n",
    "for key, value in corpus.items():\n",
    "    corpus_small[key] = value\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break\n",
    "\n",
    "# page = list(corpus_small.keys())[6] # a page in the document\n",
    "# print(corpus_small[page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba3611ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:15<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "train_queries, train_relevant_docs, val_queries, val_relevant_docs = generate_queries(corpus_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ae24082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11e2af26-4180-49ed-a665-1551884587c8': 'What are some of the rights and responsibilities of unemployed individuals according to the Merkblatt from the Agentur für Arbeit?',\n",
       " '3b034aff-62dc-4eab-b1cc-1b6f6c506b49': 'What services can individuals access through the Job and Service Portal on the Arbeitsagentur website?',\n",
       " '5d7dcf30-1f1d-4be3-beb7-e646467188fd': 'How can individuals access selected features of their online profile through the new customer app \"BA-mobil\"?',\n",
       " 'be6aa851-ece0-4e79-adfa-ca3f6d498ae6': 'What are some of the important rights and obligations that individuals need to be aware of when applying for or receiving unemployment benefits under the Third Book of the Social Code (SGB III)?',\n",
       " '564775fb-a3a8-488b-8304-b1bf7a2ac76d': 'What is the purpose of the Merkblatt Bürgergeld – Grundsicherung für Arbeit suchende – SGB II and where can it be obtained?',\n",
       " '8f593f4f-1191-4d44-9bf6-73f64ddb5ee4': 'What are the consequences of not reporting your unemployment status in a timely manner?'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ef752c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11e2af26-4180-49ed-a665-1551884587c8': ['34714d27-0488-49fa-b8e5-a7c287da38c2'],\n",
       " '3b034aff-62dc-4eab-b1cc-1b6f6c506b49': ['6d263834-c687-4214-aad5-df728e814b96'],\n",
       " '5d7dcf30-1f1d-4be3-beb7-e646467188fd': ['389a30ad-c887-4fa0-bd05-4e17a8430b06'],\n",
       " 'be6aa851-ece0-4e79-adfa-ca3f6d498ae6': ['2b3d3a74-dc55-415c-91ee-49bf16186145'],\n",
       " '564775fb-a3a8-488b-8304-b1bf7a2ac76d': ['0240a5b7-0800-4059-ab7a-67aece2a20e9'],\n",
       " '8f593f4f-1191-4d44-9bf6-73f64ddb5ee4': ['8535c3a6-7d9f-4553-86ef-36a2a560bcd3']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c62c1ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ea5a9cd7-7316-44ed-9211-0267909c4014': ['34714d27-0488-49fa-b8e5-a7c287da38c2'],\n",
       " 'd5cd98f6-0bb8-413f-b1dc-7db879c2b874': ['6d263834-c687-4214-aad5-df728e814b96'],\n",
       " '90fe076f-fd8a-433a-b28a-259b9179a9d2': ['389a30ad-c887-4fa0-bd05-4e17a8430b06'],\n",
       " '62d4675a-4a20-46ad-9d28-83c44dc618e4': ['2b3d3a74-dc55-415c-91ee-49bf16186145'],\n",
       " '76af64e4-996c-4a10-b163-24ec7580dd27': ['0240a5b7-0800-4059-ab7a-67aece2a20e9'],\n",
       " '22b466b5-59b9-4b01-9105-9d1f71a5f339': ['8535c3a6-7d9f-4553-86ef-36a2a560bcd3']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_relevant_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4418d831",
   "metadata": {},
   "source": [
    "# Create full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9452dcfc-7084-496f-87eb-8c7be6a6dc6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [06:16<00:00,  3.66s/it]\n"
     ]
    }
   ],
   "source": [
    "train_queries, train_relevant_docs, val_queries, val_relevant_docs = generate_queries(\n",
    "    corpus=corpus,\n",
    "    num_questions_per_chunk=4,\n",
    "    num_val_questions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96087eb2-607b-4115-ab37-426bfcf6af1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(train_queries_fpath, 'w+') as f:\n",
    "    json.dump(train_queries, f)\n",
    "\n",
    "with open(train_relevant_docs_fpath, 'w+') as f:\n",
    "    json.dump(train_relevant_docs, f)\n",
    "\n",
    "with open(val_queries_fpath, 'w+') as f:\n",
    "    json.dump(val_queries, f)\n",
    "\n",
    "with open(val_relevant_docs_fpath, 'w+') as f:\n",
    "    json.dump(val_relevant_docs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71453dc5-25e0-45bf-9d86-5e72b3a891d5",
   "metadata": {},
   "source": [
    "## Merge data\n",
    "\n",
    "Reorganize the data for easier accessing the training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f465498-daa5-41b3-9ea3-8114254832b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_fpath = 'data_finetuning/one_file/train_val_data/train_dataset.json'\n",
    "val_dataset_fpath = 'data_finetuning/one_file/train_val_data/val_dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "430e34b0-699d-4eec-a26d-6d100d81cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = {\n",
    "    'queries': train_queries,\n",
    "    'corpus': corpus,\n",
    "    'relevant_docs': train_relevant_docs,\n",
    "}\n",
    "\n",
    "val_dataset = {\n",
    "    'queries': val_queries,\n",
    "    'corpus': corpus,\n",
    "    'relevant_docs': val_relevant_docs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b09071a2-6c32-408a-b971-39b5d6e42486",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_dataset_fpath, 'w+') as f:\n",
    "    json.dump(train_dataset, f)\n",
    "\n",
    "with open(val_dataset_fpath, 'w+') as f:\n",
    "    json.dump(val_dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
