{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- [Karpathy’s SVM-based approach](https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb)\n",
    "- [Query Index with SVM/Linear Regression](https://gpt-index.readthedocs.io/en/stable/examples/vector_stores/SimpleIndexDemo.html#query-index) in LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index import LLMPredictor, ServiceContext\n",
    "# from llama_index import VectorStoreIndex\n",
    "# from llama_index import SimpleDirectoryReader\n",
    "from llama_index import Prompt\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "# from llama_index.llms import OpenAI\n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "import environ\n",
    "import openai\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniele/Desktop/Projects/chatbot_dsr_project/.venv_chatbot/lib/python3.10/site-packages/environ/environ.py:639: UserWarning: /tmp/ipykernel_9394/.env doesn't exist - if you're not configuring your environment separately, create one.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# For now I use my key\n",
    "env = environ.Env()\n",
    "environ.Env.read_env()\n",
    "API_KEY = env(\"OPENAI_API_KEY\")\n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt\n",
    "template = (\n",
    "    \"We have provided context information below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given this information, please answer the question and each answer should start with code word Response: {query_str}\\n\"\n",
    ")\n",
    "qa_template = Prompt(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"vector_db\")\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniele/Desktop/Projects/chatbot_dsr_project/.venv_chatbot/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/daniele/Desktop/Projects/chatbot_dsr_project/.venv_chatbot/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/daniele/Desktop/Projects/chatbot_dsr_project/.venv_chatbot/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "query_modes = [\n",
    "    \"svm\",\n",
    "    \"linear_regression\",\n",
    "    \"logistic_regression\",\n",
    "]\n",
    "\n",
    "user_query = \"I worked in Germany for 36 months and my contract will end in 4 months. How long will I receive thhe unemployment benefit?\"\n",
    "user_query = \"What is the capital of Italy?\"\n",
    "\n",
    "responses = []\n",
    "\n",
    "for query_mode in query_modes:\n",
    "# set Logging to DEBUG for more detailed outputs\n",
    "    query_engine = index.as_query_engine(\n",
    "        text_qa_template=qa_template,\n",
    "        similarity_top_k=3,\n",
    "        vector_store_query_mode=query_mode\n",
    "    )\n",
    "    responses.append(query_engine.query(user_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3739772b-b09e-47f6-a419-832e5e127f01': {'page_label': '11',\n",
       "  'file_name': 'ba146332.pdf'},\n",
       " '3cde6bc4-3be9-4130-b3be-aec08e1b946d': {'page_label': '3',\n",
       "  'file_name': 'ba146332.pdf'},\n",
       " 'd81ad49f-97b8-4567-88e3-39b5057d1c31': {'page_label': '11',\n",
       "  'file_name': 'ba146332.pdf'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query mode: svm\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Response: The capital of Italy is Rome.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Query mode: linear_regression\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Response: The capital of Italy is Rome.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Query mode: logistic_regression\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Response: The capital of Italy is Rome.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "for query, response in zip(query_modes, responses):\n",
    "    print(f\"Query mode: {query}\")\n",
    "    display(Markdown(f\"<b>{response}</b>\"))\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query mode: svm\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Response: Based on the provided information, the duration of receiving unemployment benefits in Germany depends on various factors such as the length of your employment, the reason for contract termination, and the specific circumstances of your case. It is recommended to consult with the German Federal Employment Agency (Agentur für Arbeit) for accurate and up-to-date information regarding your eligibility and the duration of unemployment benefits you may receive.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Query mode: linear_regression\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Response: Based on the provided information, the duration of receiving unemployment benefits in Germany depends on various factors such as the length of your employment, the reason for contract termination, and the specific circumstances of your case. It is recommended to consult with the German Federal Employment Agency (Agentur für Arbeit) for accurate and up-to-date information regarding your eligibility and the duration of unemployment benefits you may receive.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Query mode: logistic_regression\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Response: Based on the provided information, the duration of receiving unemployment benefits in Germany depends on various factors such as the length of your employment, the reason for contract termination, and the specific circumstances of your case. It is recommended to consult with the German Federal Employment Agency (Agentur für Arbeit) for accurate and up-to-date information regarding your eligibility and the duration of unemployment benefits you may receive.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "for query, response in zip(query_modes, responses):\n",
    "    print(f\"Query mode: {query}\")\n",
    "    display(Markdown(f\"<b>{response}</b>\"))\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query engine\n",
    "query_engine_from_loaded = index.as_query_engine(text_qa_template=qa_template, similarity_top_k=3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From GitHub\n",
    "\n",
    "Here: [Karpathy’s SVM-based approach](https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "embeddings = np.random.randn(1000, 1536) # 1000 documents, 1536-dimensional embeddings\n",
    "embeddings = embeddings / np.sqrt((embeddings**2).sum(1, keepdims=True)) # L2 normalize the rows, as is common\n",
    "\n",
    "query = np.random.randn(1536) # the query vector\n",
    "query = query / np.sqrt((query**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 results:\n",
      "row 545, similarity 0.07956628031855817\n",
      "row 790, similarity 0.0710937236589117\n",
      "row 973, similarity 0.0692079948121463\n",
      "row 597, similarity 0.0647482457550396\n",
      "row 479, similarity 0.06350781255023308\n",
      "row 229, similarity 0.061432183499702385\n",
      "row 976, similarity 0.06122285352624162\n",
      "row 568, similarity 0.06088872280511322\n",
      "row 800, similarity 0.06007081261453451\n",
      "row 654, similarity 0.05815882432824042\n"
     ]
    }
   ],
   "source": [
    "# Tired: use kNN\n",
    "similarities = embeddings.dot(query)\n",
    "sorted_ix = np.argsort(-similarities)\n",
    "print(\"top 10 results:\")\n",
    "for k in sorted_ix[:10]:\n",
    "  print(f\"row {k}, similarity {similarities[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the \"Dataset\"\n",
    "x = np.concatenate([query[None,...], embeddings]) # x is (1001, 1536) array, with query now as the first row\n",
    "y = np.zeros(1001)\n",
    "y[0] = 1 # we have a single positive example, mark it as such\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 1536)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1536)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query[None, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00802579,  0.02001674, -0.03141846, ...,  0.01385069,\n",
       "       -0.02867884, -0.02033733])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 results:\n",
      "row 0, similarity 0.9797112511386071\n",
      "row 546, similarity -0.8360649708567132\n",
      "row 791, similarity -0.8519226137351357\n",
      "row 974, similarity -0.8585435491440423\n",
      "row 480, similarity -0.8620392328630408\n",
      "row 598, similarity -0.8653314951353852\n",
      "row 230, similarity -0.8671983850173497\n",
      "row 569, similarity -0.8674761564717197\n",
      "row 977, similarity -0.8705646017047624\n",
      "row 801, similarity -0.8728033727353595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniele/Desktop/Projects/bureaubot/.venv_bureaubot/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Wired: use an SVM\n",
    "from sklearn import svm\n",
    "\n",
    "# create the \"Dataset\"\n",
    "x = np.concatenate([query[None,...], embeddings]) # x is (1001, 1536) array, with query now as the first row\n",
    "y = np.zeros(1001)\n",
    "y[0] = 1 # we have a single positive example, mark it as such\n",
    "\n",
    "# train our (Exemplar) SVM\n",
    "clf = svm.LinearSVC(class_weight='balanced', verbose=False, max_iter=10000, tol=1e-6, C=0.1)\n",
    "clf.fit(x, y) # train\n",
    "\n",
    "# infer on whatever data you wish, e.g. the original data\n",
    "similarities = clf.decision_function(x)\n",
    "sorted_ix = np.argsort(-similarities)\n",
    "print(\"top 10 results:\")\n",
    "for k in sorted_ix[:10]:\n",
    "  print(f\"row {k}, similarity {similarities[k]}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
